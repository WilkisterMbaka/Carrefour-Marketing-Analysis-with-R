---
title: "Week 14 - Dimensionality Reduction"
author: "Wilkister Mbaka"
date: "2022-07-29"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **CarreFour Marketing - Dimensionality Reduction**

## **Definining The Question**

**Specifying the Question**

1. This section of the project entails reducing your dataset to a low dimensional dataset using the t-SNE algorithm or PCA. 
2. You will be required to perform your analysis and provide insights gained from your analysis.

**Metric of success**

- Importing the data
- Cleaning the data 
- performing a thorough EDA
- Performing Dimensionality Reduction


**Data relevance**

The data has been provided by the supermarket itself


**Understanding the context**

You are a Data analyst at Carrefour Kenya and are currently undertaking a project that will inform the marketing department on the most relevant marketing strategies that will result in the highest no. of sales (total price including tax). Your project has been divided into four parts where you'll explore a recent marketing dataset by performing various unsupervised learning techniques and later providing recommendations based on your insights.

**Experimental design**

The experimental design will involve the following steps:

- Dealing with missing values. 
- Dropping variables of low variance. 
- Use of decision trees to tackle missing values, outliers and identifying significant variables. 
- Use of random forest to select a smaller subset of input features. 
- Using the Pearson correlation matrix to identify and later drop variables with high correlation. 
- Performing backward feature elimination. 
- Performing factor analysis to group high correlated variables. 
- Using Principal Component Analysis (PCA).

## **Reading The Data**

```{r}
# Importing Libraries
library (tidyr)
library(naniar)
library (ggplot2)
library (e1071)
library (corrplot)
library(factoextra)
library(NbClust)
library(superml)
```

``` {r}
#installing packages
library(data.table)
#
#Loading the dataset
df <- fread("http://bit.ly/CarreFourDataset")
```
## **Checking The Data**

```{r}
# Preview the data
head(df)
```

```{r}
# Preview the data
tail(df)
```


```{r}
# Dimensionanity of the data
dim(df)
```
The dataframe has 1000 rows and 16 columns


## **Tidying The Dataset**
```{r}
# check the column names  
colnames(df)

# standardize column names with standard naming convention ie lowercase and replace spaces with '_'
# replace the spaces with underscores using gsub() function
names(df) <- gsub(" ","_", names(df))

# The column names have a mixture of uppercase and lowercase charachers we should correct that and 
#make all the characters lowercase.
names(df) <- tolower(names(df))
# Confirmation 
colnames(df)
```

```{r}
# Let us find the datatypes of the data
str(df)
```
The dataset has character, integer and numerical datatypes
Time and date are in the incorrect format

```{r}
# Change date to date format
df$date <- as.Date(df$date, "%m/%d/%Y")

# Change time to time format

df$time <- as.ITime(df$time)

head(df)
```
``` {r}
#Finding the total number of missing values in each column
colSums(is.na(df))
```
There are no missing values in the dataset


```{r}
# Cheking for duplicates
df_dup <- df[duplicated(df),]
df_dup
```
There is no duplicate data in this dataset

**Checking for outliers**
```{r}
# Plotting boxplots to check for outliers
boxplot(df$unit_price,col='grey', main = 'Unit Price')
boxplot(df$quantity,col='grey', main = 'Quantity Boxplot')
boxplot(df$tax,col='grey', main = 'Tax')
boxplot(df$cogs,col='grey', main = 'Cogs')
boxplot(df$gross_margin_percentage,col='grey', main = 'Gross Margin Percentage')
boxplot(df$gross_income,col='grey', main = 'Gross Income')
boxplot(df$rating,col='grey', main = 'Rating')
boxplot(df$total,col='grey', main = 'Total')
```
Tax, Cogs, Gross Income, Total has some outliers but we will leave them because they are actual representation of the data

```{r}
# removing irrelevant column - gross_margin_percentage it has the same amount through out
setDT(df)[, c( 'gross_margin_percentage') := NULL]
# check the dimensions of the dataframe after cleaning
dim(df)
```


## **Exploratory Data Analysis**

### **Univariate Analysis**

#### **Categorical Variables**

```{r}
# Frequency of Branch column

ggplot(df, aes(x = branch)) +
  geom_bar(fill="blue") +  ggtitle('Barplot of Branch')

```
The data collected on Branches A is slightly more than branch B and C .

```{r}
# Frequency of Customer Type column

ggplot(df, aes(x = customer_type)) +
  geom_bar(fill="blue") +  ggtitle('Barplot of Customer Type')
```
The information collected was half from the members and half from the normal customers. 

```{r}
# Frequency of Gender column

ggplot(df, aes(x = gender)) +
  geom_bar(fill="blue") +  ggtitle('Barplot of Gender')
```
The data from male and female persons is equal

```{r fig.height=3, fig.width=6.4}
# Frequency of Product Line column

ggplot(df, aes(x = product_line)) +
  geom_bar(fill="blue") +  ggtitle('Barplot of Product Line')
```
The most popular product line is Fashion accessories followed by food and beverages

```{r}
# Frequency of Payment column

ggplot(df, aes(x = payment)) +
  geom_bar(fill="blue") +  ggtitle('Barplot of Payment')
```
Slightly More people paid their bills with E wallet and cash rather than Credit card

#### **Numerical Variables** 
```{r}
# numerical columns. 
num_col <- unlist(lapply(df, is.numeric))
df_num <- subset(df, select = num_col)
head (df_num)
```

```{r}
#Getting the measures of dispersion in the numerical columns. 
summary_stats <- data.frame(
  Mean = apply(df_num, 2, mean), 
  Median = apply(df_num, 2, median), 
  Min = apply(df_num, 2, min),  
  Max = apply(df_num, 2, max)) 
summary_stats
```

```{r}
# compute the measures of cenral tendancy and the measures of dispersion of the numerical variables and contain them in a data1frame
library(moments)
statistics <- data.frame(
Variance= apply(df_num, 2, var),
Std = apply(df_num, 2, sd),
Skewness = apply(df_num, 2, skewness),
Kurtosis = apply(df_num, 2, kurtosis))
# round off the values to 2 decimal places and display the data1frame
statistics <- round(statistics, 2)
statistics
```

```{r}
# Define the function 
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

# Mode
mode.unit_price <- getmode(df$unit_price)
mode.unit_price
mode.quantity <- getmode(df$quantity)
mode.quantity
mode.tax <- getmode(df$tax)
mode.tax
mode.cogs <- getmode(df$cogs)
mode.cogs
mode.gross_income <- getmode(df$gross_income)
mode.gross_income
mode.rating <- getmode(df$rating)
mode.rating
mode.total  <- getmode(df$total)
mode.total
```

**Histograms for Numerical Variables**
```{r}
# plot a histogram to visualize the distribution of values in 'Unit Price' column
hist(df$unit_price,
    col="#660033",
    main="Histogram to Show Count of Unit Price",
    xlab="Unit Price",
    ylab="Frequency",
    labels=TRUE)
```
More items have a unit price of 90 - 100

```{r}
# plot a histogram to visualize the distribution of values in 'Quantity' column
hist(df$quantity,
    col="#660033",
    main="Histogram to Show Count of Quantity",
    xlab="Quantity",
    ylab="Frequency",
    labels=TRUE)
```
Most customers bought 1 item at a time

```{r}
# plot a histogram to visualize the distribution of values in 'Tax' column
hist(df$tax,
    col="#660033",
    main="Histogram to Show Count of Tax",
    xlab="Tax",
    ylab="Frequency",
    labels=TRUE)
```
The tax bracket 0 - 5 had a higher number of items 

```{r}
# plot a histogram to visualize the distribution of values in 'Cogs' column
hist(df$cogs,
    col="#660033",
    main="Histogram to Show Count of Cogs",
    xlab="Cogs",
    ylab="Frequency",
    labels=TRUE)
```
Cogs (Cost of goods sold) The items cost bracket of 0 - 100 has the higher amount of items

Tax and Cogs have a similar histogram

```{r}
# plot a histogram to visualize the distribution of values in 'Gross Income' column

hist(df$gross_income,
    col="#660033",
    main="Histogram to Show Count of Gross Income",
    xlab="Gross Income",
    ylab="Frequency",
    labels=TRUE)
```
Gross Income, Tax and Cogs have a similar histogram

```{r}
# plot a histogram to visualize the distribution of values in 'Rating' column

hist(df$rating,
    col="#660033",
    main="Histogram to Show Count of Rating",
    xlab="Rating",
    ylab="Frequency",
    labels=TRUE)
```
The rating 4 - 4.5 had higher amount of items than other rating brackets

```{r}
# plot a histogram to visualize the distribution of values in 'total' column

hist(df$total,
    col="#660033",
    main="Histogram to Show Count of Total",
    xlab="Total",
    ylab="Frequency",
    labels=TRUE)
```
A higher number of items fell into the total price bracket 0 - 100


## **Bivariate Analysis**

**Payment method frequency in every branch**
```{r}
# Create barplot

ggplot(df, aes(fill=payment, x=branch)) +
    geom_bar(position="stack")
```
Most popular method of payment in Branch A is E-wallet

Most popular method of payment in Branch B is E-wallet but the other 2 modes of payment are also popular

Most popular method of payment in Branch B is Cash


**Product line Frequency in every branch**
```{r}
# Create Barplot

ggplot(df, aes(fill=product_line, x=branch)) +
    geom_bar(position="dodge")
```

From the plot, Branch B sells more sports & travel and Health & Beauty goods than the other branches. 
Branch A sells more home and lifestyle goods than the other branches. 
Branch c sells more Food & Beverages, Fashion Accessories and Electronic accessories than the other branches
Therefore, the marketing team should stack these branches with the product with which they sell more. 

**Gender Frequency in every branch**
```{r}
ggplot(df, aes(fill=gender, x=branch)) + 
    geom_bar(position="dodge")
```
There are more males in the Carrefour branches A and B than the females. This is not what many people assume as many people erroneously think that there are usually more females doing shopping. 
In branch C, there are more females shopping than males
```{r}
head(df)
```

**Mean Rating for items every branch**
```{r}
# calculate mean rating for each branch
library(dplyr)
plotdata <- df %>%
  group_by(branch) %>%
  summarize(mean_rating = mean(rating))

# plot mean salaries
ggplot(plotdata, aes(x = branch, y = mean_rating)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  geom_text(aes(label = round(mean_rating,2)), 
            vjust = -0.25)
```
Branch C has a higher mean rating of the product line items than the other branches

**Mean Rating for items in every product line **
```{r}
# calculate mean rating for each product line
library(dplyr)
plotdata1 <- df %>%
  group_by(product_line) %>%
  summarize(mean_rating = mean(rating))

# plot mean salaries
ggplot(plotdata1, aes(x = product_line, y = mean_rating)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  geom_text(aes(label = round(mean_rating,2)), 
            vjust = -0.25)
```
Food and Beverages has the highest rating and Home & Lifestyle has the least rating

```{r}
# calculate correlations
correlations <- cor(df_num)
# create correlation plot
corrplot(correlations, method="number")
```
Gross income, tax, cogs and total have a correlation of 1 because they are calculated from from the same starting point (Cogs) and with the same fractions for tax, gross income and total.
```{r}
# Label Encoder
#Branch , customer_type, Gender, productline , payment
lbl <- LabelEncoder$new()
lbl$fit(df$branch)
df$branch <- lbl$fit_transform(df$branch)
lbl$fit(df$customer_type)
df$customer_type <- lbl$fit_transform(df$customer_type)
lbl$fit(df$gender)
df$gender <- lbl$fit_transform(df$gender)
lbl$fit(df$product_line)
df$product_line <- lbl$fit_transform(df$product_line)
lbl$fit(df$payment)
df$payment <- lbl$fit_transform(df$payment)
```

```{r}
str(df)
```
```{r}
# Since the gross margin percentage has only one value we can drop the column. 
table(df$gross_margin_percentage)
df$gross_margin_percentage <- NULL
```

```{r}
# Drop the categorcal columns 
df$invoice_id <- NULL
df$date <- NULL
df$time <- NULL
```

```{r}
# Separate the data 
df.x <-  df[ , 1:11]
df.y <-  df[, 12]
```

```{r}
head(df.x)
head(df.y)
```

```{r}
# perform tsne
library(Rtsne)
tsne = Rtsne(df.x, dims = 2,  perplexity = 30)
```

```{r}
#visualize TSNE
df.tsne = data.frame(tsne$Y)  
ggplot(df.tsne, aes(x=X1, y=X2)) + geom_point(size=2)
```
## Performing the PCA

```{r}
# Run the PCA on the df
dfpca <- prcomp(t(df),center = TRUE, scale=TRUE) 
## plot pc1 and pc2
plot(dfpca$x[,1], dfpca$x[,2], main = "PCA1 & PCA2 values")
```

```{r}
# Lets get a summary of the pca
summary (dfpca)
```
```{r}
## make a scree plot
pca.var <- dfpca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
barplot(pca.var.per, main="Scree Plot", xlab="Principal Component", ylab="Percent Variation")
```


```{r}
## plot that shows the PCs and the variation:
pca.data <- data.frame(Sample=rownames(dfpca$x),
                       X=dfpca$x[,1],
                       Y=dfpca$x[,2])
pca.data
ggplot(data=pca.data, aes(x=X, y=Y, label=Sample)) +
  geom_text() +
  xlab(paste("PC1 - ", pca.var.per[1], "%", sep="")) +
  ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
  theme_bw() +
  ggtitle("Customer Data PCA Graph")
```
PC1 explains 96.5% of the total variance, which means that nearly 96% 
 of the information in the dataset (11 variables) can be encapsulated 
 by just that one Principal Component. PC2 explains 3.3% of the variance. etc
```{r}
library(ggbiplot)
ggbiplot (prcomp(df))
```